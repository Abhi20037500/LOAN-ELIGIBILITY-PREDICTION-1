# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ux-ObU_ZAt2rHAW79IJz2UbgS1nAHDip
"""

# app.py
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
from io import BytesIO

st.set_page_config(page_title="Loan Eligibility Predictor", layout="wide", initial_sidebar_state="expanded")

# ---------- Helper functions ----------
@st.cache_resource
def load_model(path="model.pkl"):
    if os.path.exists(path):
        with open(path, "rb") as f:
            return pickle.load(f)
    return None

@st.cache_resource
def load_scaler(path="scaler.pkl"):
    if os.path.exists(path):
        with open(path, "rb") as f:
            return pickle.load(f)
    return None

def preprocess_single(input_df, scaler=None, cols_order=None):
    """
    Preprocess the single-row dataframe to match model features.
    Update this function if your model needs different preprocessing.
    """
    df = input_df.copy()
    # Example simple preprocessing: encode gender/married/education etc.
    # Change the mappings to match what your model expects.
    mappings = {
        "Gender": {"Male": 1, "Female": 0},
        "Married": {"Yes": 1, "No": 0},
        "Education": {"Graduate": 1, "Not Graduate": 0},
        "Self_Employed": {"Yes": 1, "No": 0},
        "Property_Area": {"Urban": 2, "Semiurban": 1, "Rural": 0}
    }
    for col, mp in mappings.items():
        if col in df.columns:
            df[col] = df[col].map(mp).fillna(0)

    # If you have categorical variables not mapped here, add them.

    # Reorder columns if model expects specific order
    if cols_order:
        missing = [c for c in cols_order if c not in df.columns]
        if missing:
            # if missing, add zeros (safe fallback)
            for c in missing:
                df[c] = 0
        df = df[cols_order]

    # Scale numeric columns if scaler provided
    if scaler is not None:
        try:
            scaled = scaler.transform(df.values)
            df = pd.DataFrame(scaled, columns=df.columns)
        except Exception:
            # If scaler doesn't match, ignore
            pass

    return df

def predict(model, X):
    """
    Return (label, proba) - label: 1 or 0
    """
    if model is None:
        # fallback simple rule (example):
        # If ApplicantIncome / LoanAmount ratio is high and credit history present -> eligible
        ai = X.get("ApplicantIncome", 0)
        la = X.get("LoanAmount", 1)
        ch = X.get("Credit_History", 0)
        score = (ai / (la + 1)) + (ch * 10)
        label = 1 if score > 20 else 0
        proba = min(0.99, max(0.01, score / 30.0))
        return label, proba
    try:
        if hasattr(model, "predict_proba"):
            proba = model.predict_proba(X)[:, 1][0]
            label = int(model.predict(X)[0])
            return label, float(proba)
        else:
            label = int(model.predict(X)[0])
            return label, 1.0 if label == 1 else 0.0
    except Exception as e:
        st.error(f"Prediction error: {e}")
        return None, None

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="predictions")
        writer.save()
    processed_data = output.getvalue()
    return processed_data

# ---------- Load model & scaler ----------
model = load_model("model.pkl")
scaler = load_scaler("scaler.pkl")

# ---------- Sidebar ----------
st.sidebar.image("https://static.streamlit.io/examples/dice.jpg", use_column_width=True)  # replace with your logo if you want
st.sidebar.title("Loan Eligibility System")
st.sidebar.markdown("""
A simple interface to test loan eligibility predictions.
- Provide applicant details
- Or upload a CSV with multiple applicants
""")
st.sidebar.markdown("**Model loaded:** " + ("✅" if model is not None else "❌ - using fallback rule"))
st.sidebar.markdown("**Scaler loaded:** " + ("✅" if scaler is not None else "❌"))

# ---------- Main layout ----------
st.title("Loan Eligibility Predictor")
st.write("Fill the applicant details on the left and click **Predict**. Upload a CSV for batch predictions.")

col1, col2 = st.columns([2, 3])

with col1:
    st.header("Applicant Information")
    with st.form(key="single_form"):
        name = st.text_input("Applicant Name", placeholder="e.g., John Doe")
        gender = st.selectbox("Gender", ["Male", "Female"])
        married = st.selectbox("Married", ["No", "Yes"])
        dependents = st.selectbox("Dependents", ["0", "1", "2", "3+"])
        education = st.selectbox("Education", ["Graduate", "Not Graduate"])
        self_employed = st.selectbox("Self Employed", ["No", "Yes"])
        applicant_income = st.number_input("Applicant Income (monthly)", min_value=0.0, value=25000.0, step=500.0)
        coapplicant_income = st.number_input("Coapplicant Income (monthly)", min_value=0.0, value=0.0, step=500.0)
        loan_amount = st.number_input("Loan Amount (total)", min_value=0.0, value=100.0, step=50.0)
        loan_term = st.number_input("Loan Term (months)", min_value=0, value=360, step=12)
        credit_history = st.selectbox("Credit History", [1.0, 0.0], format_func=lambda x: "Good (1.0)" if x == 1.0 else "Bad (0.0)")
        property_area = st.selectbox("Property Area", ["Urban", "Semiurban", "Rural"])

        submit_button = st.form_submit_button(label="Predict")

with col2:
    st.header("Prediction & Explanation")
    result_box = st.empty()
    explanation = st.empty()

    if submit_button:
        # Build input DF matching typical training features
        input_dict = {
            "Gender": gender,
            "Married": married,
            "Dependents": dependents,
            "Education": education,
            "Self_Employed": self_employed,
            "ApplicantIncome": applicant_income,
            "CoapplicantIncome": coapplicant_income,
            "LoanAmount": loan_amount,
            "Loan_Amount_Term": loan_term,
            "Credit_History": credit_history,
            "Property_Area": property_area
        }
        input_df = pd.DataFrame([input_dict])

        # If your model needs different columns/order, set cols_order accordingly
        # Example column order used by many UCI-like samples:
        cols_order = ["Gender","Married","Dependents","Education","Self_Employed",
                      "ApplicantIncome","CoapplicantIncome","LoanAmount","Loan_Amount_Term",
                      "Credit_History","Property_Area"]

        X = preprocess_single(input_df, scaler=scaler, cols_order=cols_order)

        label, proba = predict(model, X)
        if label is None:
            result_box.error("Could not compute prediction.")
        else:
            if label == 1:
                result_box.success(f"✅ **Eligible** — Probability: {proba*100:.1f}%")
            else:
                result_box.error(f"❌ **Not Eligible** — Probability: {proba*100:.1f}%")

            # short explanation
            expl_lines = []
            expl_lines.append(f"**Applicant:** {name or '—'}")
            expl_lines.append(f"- Applicant Income: {applicant_income}")
            expl_lines.append(f"- Loan Amount: {loan_amount}")
            expl_lines.append(f"- Credit History: {'Good' if credit_history == 1.0 else 'Bad'}")
            # Add a few heuristic notes (these are example heuristics)
            ratio = applicant_income / (loan_amount + 1)
            if ratio < 50:
                expl_lines.append("- Income-to-loan ratio is low (may reduce eligibility).")
            else:
                expl_lines.append("- Income-to-loan ratio looks healthy.")
            if credit_history == 0.0:
                expl_lines.append("- Credit history is poor; lenders often require good credit.")
            explanation.markdown("\n".join(expl_lines))

# ---------- Batch Upload ----------
st.markdown("---")
st.subheader("Batch prediction (CSV upload)")
st.markdown("Upload a CSV with same columns as the form — we'll run predictions for every row.")

upload_col, template_col = st.columns([3,1])
with upload_col:
    uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.write("Preview of uploaded data:")
            st.dataframe(df.head())
            # Preprocess entire df (assumes df contains required columns)
            cols_order = ["Gender","Married","Dependents","Education","Self_Employed",
                          "ApplicantIncome","CoapplicantIncome","LoanAmount","Loan_Amount_Term",
                          "Credit_History","Property_Area"]
            X_batch = preprocess_single(df, scaler=scaler, cols_order=cols_order)
            # Predict
            if model is None:
                # fallback for batch
                preds = []
                probs = []
                for idx, row in df.iterrows():
                    label, proba = predict(None, row.to_dict())
                    preds.append(label)
                    probs.append(proba)
            else:
                try:
                    probs = model.predict_proba(X_batch)[:, 1]
                    preds = model.predict(X_batch)
                except Exception:
                    # fall back to single-row predict loop
                    preds = []
                    probs = []
                    for i in range(len(X_batch)):
                        lab, pr = predict(model, X_batch.iloc[[i]])
                        preds.append(lab)
                        probs.append(pr)

            df["Prediction"] = ["Eligible" if int(p) == 1 else "Not Eligible" for p in preds]
            df["Probability"] = [float(p) for p in probs]
            st.success("Batch prediction finished.")
            st.dataframe(df.head(20))

            # Download results
            excel_bytes = to_excel(df)
            st.download_button("Download predictions (Excel)", data=excel_bytes, file_name="predictions.xlsx")
        except Exception as e:
            st.error(f"Failed to process CSV: {e}")

with template_col:
    st.write("Download template")
    template_df = pd.DataFrame([{
        "Gender":"Male",
        "Married":"Yes",
        "Dependents":"0",
        "Education":"Graduate",
        "Self_Employed":"No",
        "ApplicantIncome":25000,
        "CoapplicantIncome":0,
        "LoanAmount":100,
        "Loan_Amount_Term":360,
        "Credit_History":1.0,
        "Property_Area":"Urban"
    }])
    st.download_button("Download CSV template", data=template_df.to_csv(index=False).encode('utf-8'),
                       file_name="loan_template.csv", mime="text/csv")

# ---------- Footer / Notes ----------
st.markdown("---")
st.caption("Note: This interface expects that your model was trained on features similar to the ones shown. "
           "If your notebook used different preprocessing (one-hot encoding, engineered features, different column names), adapt "
           "`preprocess_single()` accordingly. If you want, share your notebook and I can adapt this code to the exact pipeline.")



pip install streamlit

import pickle

# Save trained model
with open("model.pkl", "wb") as f:
    pickle.dump(model, f)

# (Optional) If you used a scaler:
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)